{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee9b54c636b51e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:38:51.662765Z",
     "start_time": "2025-02-26T19:38:51.658593Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import load_tools\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools import ShellTool\n",
    "from langchain_community.tools import BraveSearch\n",
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.types import Command\n",
    "\n",
    "load_dotenv()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c6778-403b-4b49-9b93-678e910d5cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:38:52.507342Z",
     "start_time": "2025-02-26T19:38:52.118494Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-latest\", max_retries=5)\n",
    "\n",
    "bash_tool = ShellTool()\n",
    "search_tool = BraveSearch.from_api_key(api_key=os.getenv(\"BRAVE_API_KEY\"), search_kwargs={\"count\": 3})\n",
    "fs_tool = FileManagementToolkit(root_dir=\"./\").get_tools()\n",
    "human = load_tools(\n",
    "    [\"human\"],\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32962d2-5487-496d-aefc-2a3b0d194985",
   "metadata": {},
   "source": [
    "### Agent Supervisor\n",
    "\n",
    "It will use LLM with structured output to choose the next worker node OR finish processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bd80b-c477-4d74-8faa-1c0548622239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:38:54.851950Z",
     "start_time": "2025-02-26T19:38:54.846537Z"
    }
   },
   "outputs": [],
   "source": [
    "team_members = [\"frontend developer\", \"backend developer\", \"devops engineer\"]\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process and decides when the work is completed\n",
    "options = team_members + [\"FINISH\"]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    f\" following workers: {team_members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "\n",
    "available_tools = [bash_tool, search_tool] + fs_tool + human\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "    next: Literal[*options]\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "\n",
    "def supervisor_node(state: State) -> Command[Literal[*team_members, \"__end__\"]]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "\n",
    "    return Command(goto=goto, update={\"next\": goto})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07d507f-34d1-4f1b-8dde-5e58d17b2166",
   "metadata": {},
   "source": [
    "## Apes together strong ðŸ¦ðŸ¦ðŸ¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a430af7-8fce-4e66-ba9e-d940c1bc48e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:39:22.827492Z",
     "start_time": "2025-02-26T19:39:22.761227Z"
    }
   },
   "outputs": [],
   "source": [
    "frontend_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=available_tools,\n",
    "    prompt=(\n",
    "        \"You are a frontend developer. Create frontend applications in framework \"\n",
    "        \"requested by user. Frontend should work together with backend created by\"\n",
    "        \" backend developer. You can ask backend or devops engineer for help\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "async def frontend_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = await frontend_agent.ainvoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"frontend developer\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "backend_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=available_tools,\n",
    "    prompt=(\n",
    "        \"You are a backend developer. Create backend part of the applications in framework \"\n",
    "        \"requested by user. Backend should work together with frontend created by frontend \"\n",
    "        \"developer. You can ask frontend or devops engineer for help\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "async def backend_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = await backend_agent.ainvoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"backend developer\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "devops_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=available_tools,\n",
    "    prompt=(\n",
    "        \"You are a devops engineer. Help backend and frontend engineers to deploy their \"\n",
    "        \"applications as instructed in the user request. You can ask frontend or backend \"\n",
    "        \"engineer any clarification questions about their code\"\n",
    "    )\n",
    ")\n",
    "\n",
    "async def devops_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = await devops_agent.ainvoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"devops engineer\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "builder.add_node(\"frontend developer\", frontend_node)\n",
    "builder.add_node(\"backend developer\", backend_node)\n",
    "builder.add_node(\"devops engineer\", devops_node)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0175fe14-5854-4197-b7e8-559335d0f81b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:38:59.357899Z",
     "start_time": "2025-02-26T19:38:59.076814Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36496de-7121-4c49-8cb6-58c943c66628",
   "metadata": {},
   "source": [
    "## Run the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba78e9-d9c1-457c-a073-d606d5d3e013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:41:43.851922Z",
     "start_time": "2025-02-26T19:39:24.774922Z"
    }
   },
   "outputs": [],
   "source": [
    "user_prompt = (\n",
    "    \"I want to build a website for a conference, it should have several pages, \"\n",
    "    \"namely: 1. Intro page about conference, 2. Page for people to submit their talks, \"\n",
    "    \"3. Page with submitted talks. Frontend part needs to be written in react, backend - in fastapi. \"\n",
    "    \"I want to store the submissions in postgresql database. \"\n",
    "    \"In the end run the project in docker and docker compose and give me the local url to test. \"\n",
    "    \"You can ask human client for any clarifications\"\n",
    ")\n",
    "async for s in graph.astream(\n",
    "    {\"messages\": [(\"user\", user_prompt)]},\n",
    "    {\"recursion_limit\": 100},\n",
    "    subgraphs=True,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a83f64-338f-4670-a49e-3c9a815e46b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
